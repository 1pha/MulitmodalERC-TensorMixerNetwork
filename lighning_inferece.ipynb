{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "from typing import List, Dict\n",
    "\n",
    "import hydra\n",
    "import omegaconf\n",
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "from tqdm.auto import tqdm\n",
    "from torch import nn\n",
    "from torchmetrics import Accuracy, AUROC, ConcordanceCorrCoef, F1Score\n",
    "import wandb\n",
    "\n",
    "import erc\n",
    "import os\n",
    "import random\n",
    "import numpy as np \n",
    "\n",
    "logger = erc.utils.get_logger(name=__name__)\n",
    "\n",
    "\n",
    "class ERCModule(pl.LightningModule):\n",
    "    def __init__(self,\n",
    "                 model: nn.Module,\n",
    "                 train_loader: torch.utils.data.DataLoader,\n",
    "                 valid_loader: torch.utils.data.DataLoader,\n",
    "                 optimizer: omegaconf.DictConfig,\n",
    "                 scheduler: omegaconf.DictConfig = None,\n",
    "                 load_from_checkpoint: str = None,\n",
    "                 separate_lr: dict = None):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "\n",
    "        # Dataloaders\n",
    "        self.train_loader = train_loader\n",
    "        self.valid_loader = valid_loader\n",
    "\n",
    "        # Optimizations\n",
    "        if separate_lr is not None:\n",
    "            _opt_groups = []\n",
    "            for _submodel, _lr in separate_lr.items():\n",
    "                submodel = getattr(self.model, _submodel, None)\n",
    "                if submodel is None:\n",
    "                    logger.warn(\"separate_lr was given but submodel was not found: %s\", _submodel)\n",
    "                    self.opt_config = self._configure_optimizer(optimizer=optimizer,\n",
    "                                                                scheduler=scheduler)\n",
    "                    break\n",
    "                _opt_groups.append(\n",
    "                    {\"params\": submodel.parameters(), \"lr\": _lr}\n",
    "                )\n",
    "            opt = dict(optimizer)\n",
    "            _o = opt.pop(\"_target_\").split(\".\")\n",
    "            _oc = importlib.import_module(\".\".join(_o[:-1]))\n",
    "            _oc = getattr(_oc, _o[-1])\n",
    "            _opt = _oc(params=_opt_groups, **opt)\n",
    "            _sch = hydra.utils.instantiate(scheduler, scheduler={\"optimizer\": _opt})\n",
    "            self.opt_config = {\"optimizer\": _opt, \"lr_scheduler\": dict(**_sch)}\n",
    "        else:\n",
    "            self.opt_config = self._configure_optimizer(optimizer=optimizer, scheduler=scheduler)\n",
    "\n",
    "        # Metrics Configuration\n",
    "        self.acc = Accuracy(task=\"multiclass\", num_classes=7)\n",
    "        self.auroc = AUROC(task=\"multiclass\", num_classes=7)\n",
    "        self.f1 = F1Score(task=\"multiclass\", num_classes=7, average=\"macro\")\n",
    "        self.ccc_val = ConcordanceCorrCoef(num_outputs=1)\n",
    "        self.ccc_aro = ConcordanceCorrCoef(num_outputs=1)\n",
    "\n",
    "        self.label_keys = list(erc.constants.emotion2idx.keys())[:-1]\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return self.train_loader\n",
    "\n",
    "    def valid_dataloader(self):\n",
    "        return self.valid_loader\n",
    "\n",
    "    def _configure_optimizer(self, optimizer: omegaconf.DictConfig, scheduler: omegaconf.DictConfig):\n",
    "        opt = hydra.utils.instantiate(optimizer, params=self.model.parameters())\n",
    "        sch: dict = hydra.utils.instantiate(scheduler, scheduler={\"optimizer\": opt})\\\n",
    "                            if scheduler is not None else None\n",
    "        opt_config = {\n",
    "            \"optimizer\": opt, \"lr_scheduler\": dict(**sch)\n",
    "        } if sch is not None else opt\n",
    "        return opt_config\n",
    "    \n",
    "    def configure_optimizers(self) -> torch.optim.Optimizer | dict:\n",
    "        return self.opt_config\n",
    "\n",
    "    def get_label(self, batch: dict, task: erc.constants.Task = None):\n",
    "        task = task or self.model.TASK\n",
    "        if task == erc.constants.Task.CLS:\n",
    "            # (batch_size,) | Long\n",
    "            labels = batch[\"emotion\"].long()\n",
    "        elif task == erc.constants.Task.REG:\n",
    "            # (batch_size, 2) | Float\n",
    "            labels = torch.stack([batch[\"valence\"], batch[\"arousal\"]], dim=1).float()\n",
    "        elif task == erc.constants.Task.ALL:\n",
    "            labels = {\n",
    "                \"emotion\": batch[\"emotion\"],\n",
    "                \"regress\": torch.stack([batch[\"valence\"], batch[\"arousal\"]], dim=1),\n",
    "                \"vote_emotion\": batch.get(\"vote_emotion\", None)\n",
    "            }\n",
    "        # TODO: Add Multilabel Fetch\n",
    "        return labels\n",
    "\n",
    "    def forward(self, batch):\n",
    "        try:\n",
    "            labels = self.get_label(batch)\n",
    "            result: dict = self.model(wav=batch[\"wav\"],\n",
    "                                      wav_mask=batch[\"wav_mask\"],\n",
    "                                      txt=batch[\"txt\"],\n",
    "                                      txt_mask=batch[\"txt_mask\"],\n",
    "                                      labels=labels,\n",
    "                                      gender=batch.get(\"gender\", None))\n",
    "            return result\n",
    "        except RuntimeError:\n",
    "            # For CUDA Device-side asserted error\n",
    "            print(f\"Label given {labels}\")\n",
    "            logger.warn(\"Label given %s\", labels)\n",
    "            raise RuntimeError\n",
    "\n",
    "    def _sort_outputs(self, outputs: List[Dict]):\n",
    "        try:\n",
    "            result = dict()\n",
    "            keys: list = outputs[0].keys()\n",
    "            for key in keys:\n",
    "                data = outputs[0][key]\n",
    "                if data.ndim == 0:\n",
    "                    # Scalar value result\n",
    "                    result[key] = torch.stack([o[key] for o in outputs if key in o])\n",
    "                elif data.ndim in [1, 2]:\n",
    "                    # Batched \n",
    "                    result[key] = torch.concat([o[key] for o in outputs if key in o])\n",
    "        except AttributeError:\n",
    "            logger.warn(\"Error provoking data %s\", outputs)\n",
    "            breakpoint()\n",
    "        return result\n",
    "\n",
    "    def remove_deuce(self, outputs: dict) -> dict:\n",
    "        \"\"\" Find deuced emotions and remove from batch \"\"\"\n",
    "        result = outputs\n",
    "        emotion = outputs[\"emotion\"]\n",
    "        if emotion.ndim == 2:\n",
    "            # For multi-dimensional emotion cases\n",
    "            _, num_class = emotion.shape\n",
    "            v, _ = emotion.max(dim=1)\n",
    "            v = v.unsqueeze(dim=1).repeat(1, num_class)\n",
    "            um = (emotion == v).sum(dim=1) == 1 # (bsz, ), unique mask\n",
    "            if (um.sum() == 0).item():\n",
    "                # If every batches had deuce data\n",
    "                # Return scalar metrics only (removing cls/reg pred and logits)\n",
    "                result = {k: _v for k, _v in outputs.items() if _v.ndim == 0}\n",
    "            else:\n",
    "                result.update(\n",
    "                    {k: _v[um] for k, _v in outputs.items() if _v.ndim > 0}\n",
    "                )\n",
    "                result[\"emotion\"] = result[\"emotion\"].argmax(dim=1)\n",
    "            return result\n",
    "        else:\n",
    "            return result\n",
    "\n",
    "    def log_result(\n",
    "        self, \n",
    "        outputs: List[Dict] | dict, \n",
    "        mode: erc.constants.RunMode | str = \"train\",\n",
    "        unit: str = \"epoch\"\n",
    "    ):\n",
    "        result: dict = self._sort_outputs(outputs=outputs) if isinstance(outputs, list) else outputs\n",
    "        if unit == \"step\":\n",
    "            # No need to on epochs\n",
    "            result = self.remove_deuce(outputs=result)\n",
    "\n",
    "        # Log Losses\n",
    "        for loss_key in [\"loss\", \"cls_loss\", \"reg_loss\"]:\n",
    "            if loss_key in result:\n",
    "                self.log(f\"{unit}/{mode}_{loss_key}\", torch.mean(result.get(loss_key, 0)), prog_bar=True)\n",
    "\n",
    "        # Log Classification Metrics: Accuracy & AUROC\n",
    "        if \"cls_pred\" in result and \"emotion\" in result:\n",
    "            self.acc(preds=result[\"cls_pred\"], target=result[\"emotion\"])\n",
    "            self.auroc(preds=result[\"cls_pred\"], target=result[\"emotion\"])\n",
    "            self.f1(preds=result[\"cls_pred\"], target=result[\"emotion\"])\n",
    "            self.log(f'{unit}/{mode}_acc', self.acc)\n",
    "            self.log(f'{unit}/{mode}_auroc', self.auroc)\n",
    "            self.log(f'{unit}/{mode}_f1', self.f1)\n",
    "\n",
    "        # Log Regression Metrics: CCC\n",
    "        if \"reg_pred\" in result and \"regress\" in result:\n",
    "            self.ccc_val(result[\"reg_pred\"][:, 0], result[\"regress\"][:, 0])\n",
    "            self.ccc_aro(result[\"reg_pred\"][:, 1], result[\"regress\"][:, 1])\n",
    "            self.log(f\"{unit}/{mode}_ccc(val)\", self.ccc_val)\n",
    "            self.log(f\"{unit}/{mode}_ccc(aro)\", self.ccc_aro)\n",
    "        return result\n",
    "        \n",
    "    def log_confusion_matrix(self, result: dict):\n",
    "        preds = result[\"cls_pred\"].cpu().detach() if \"cls_pred\" in result else None\n",
    "        labels = result[\"emotion\"].cpu().numpy() if \"emotion\" in result else None\n",
    "        if preds is not None and labels is not None:\n",
    "            preds = preds.argmax(dim=1).numpy()\n",
    "            cf = wandb.plot.confusion_matrix(y_true=labels,\n",
    "                                            preds=preds,\n",
    "                                            class_names=self.label_keys)\n",
    "            self.logger.experiment.log({\"confusion_matrix\": cf})\n",
    "\n",
    "    def training_step(self, batch, batch_idx, optimizer_idx=None):\n",
    "        result = self.forward(batch)\n",
    "        result = self.log_result(outputs=result, mode=\"train\", unit=\"step\")\n",
    "        return result\n",
    "\n",
    "    def training_epoch_end(self, outputs: List[Dict]):\n",
    "        result = self.log_result(outputs=outputs, mode=\"train\", unit=\"epoch\")\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        result = self.forward(batch)\n",
    "        result = self.log_result(outputs=result, mode=\"valid\", unit=\"step\")\n",
    "        return result\n",
    "    \n",
    "    def validation_epoch_end(self, outputs: List[Dict]):\n",
    "        result = self.log_result(outputs=outputs, mode=\"valid\", unit=\"epoch\")\n",
    "        self.log_confusion_matrix(result)\n",
    "\n",
    "def _seed_everything(seed):\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    # torch.use_deterministic_algorithms(True)\n",
    "    # If the above line is uncommented, we get the following RuntimeError:\n",
    "    #  max_pool3d_with_indices_backward_cuda does not have a deterministic implementation\n",
    "    torch.backends.cudnn.benchmark = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_from_disk\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np \n",
    "\n",
    "_seed_everything(42)\n",
    "BATCH_SIZE = 6\n",
    "valid_dataset = load_from_disk(\"/home/hoesungryu/etri-erc/kemdy19-kemdy20_valid4_multilabelFalse_rdeuceTrue\")\n",
    "train_dataset = load_from_disk(\"/home/hoesungryu/etri-erc/kemdy19-kemdy20_train4_multilabelFalse_rdeuceTrue\")\n",
    "\n",
    "valid_dataloadaer = DataLoader(valid_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "train_dataloadaer = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hydra import compose, initialize\n",
    "\n",
    "with initialize(version_base=None, config_path=\"./config/model\"):\n",
    "    cfg = compose(config_name=\"mlp_mixer_roberta\")\n",
    "\n",
    "cfg.config['txt'] = \"klue/roberta-large\"\n",
    "cfg['_target_'] = \"erc.model.mlp_mixer.MLP_Mixer_Roberta\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with initialize(version_base=None, config_path=\"./config\"):\n",
    "    config_ = compose(config_name=\"train.yaml\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from erc.model.mlp_mixer import MLP_Mixer_Roberta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterions_dict = {\n",
    "    'cls': 'erc.optims.FocalLoss',\n",
    "    'reg': 'torch.nn.MSELoss'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import AdamW\n",
    "\n",
    "model = ERCModule(\n",
    "    model = MLP_Mixer_Roberta(cfg.config, criterions = criterions_dict),\n",
    "    optimizer=config_.optim,\n",
    "    scheduler=config_.scheduler,\n",
    "    train_loader=train_dataloadaer,\n",
    "    valid_loader=valid_dataloadaer\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CKPT = '/home/hoesungryu/etri-erc/outputs/2023-04-08/13-23-20/61299-valid_acc0.949.ckpt'\n",
    "ckpt = torch.load(CKPT, map_location = torch.device('cuda:1'))\n",
    "model_ckpt = ckpt.pop(\"state_dict\")\n",
    "device = torch.device('cuda:1')\n",
    "model.to(device).load_state_dict(model_ckpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def setup_trainer(config: omegaconf.DictConfig) -> pl.LightningModule:\n",
    "    logger.info(\"Start Setting up\")\n",
    "    erc.utils._seed_everything(config.misc.seed)\n",
    "\n",
    "    ckpt = config.module.load_from_checkpoint\n",
    "    if ckpt:\n",
    "        ckpt = torch.load(ckpt)\n",
    "        model_ckpt = ckpt.pop(\"state_dict\")\n",
    "    else:\n",
    "        model_ckpt = None\n",
    "\n",
    "    logger.info(\"Start intantiating Models & Optimizers\")\n",
    "    model = hydra.utils.instantiate(config.model, checkpoint=model_ckpt)\n",
    "\n",
    "    logger.info(\"Start instantiating dataloaders\")\n",
    "    dataloaders = erc.datasets.get_dataloaders(ds_cfg=config.dataset,\n",
    "                             dl_cfg=config.dataloader,\n",
    "                             modes=config.misc.modes)\n",
    "    \n",
    "    logger.info(\"Start instantiating Pytorch-Lightning Trainer\")\n",
    "\n",
    "\n",
    "    module = hydra.utils.instantiate(config.module,\n",
    "                                    model=model,\n",
    "                                    optimizer=config.optim,\n",
    "                                    scheduler=config.scheduler,\n",
    "                                    train_loader=dataloaders[\"train\"],\n",
    "                                    valid_loader=dataloaders[\"valid\"])\n",
    "\n",
    "    return module, dataloaders\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label(batch: dict, task: erc.constants.Task = None):\n",
    "    device = torch.device('cuda:1')\n",
    "    # labels = batch[\"emotion\"].long()\n",
    "    # labels = torch.stack([batch[\"valence\"], batch[\"arousal\"]], dim=1).float()\n",
    "    labels = {\n",
    "    # \"emotion\": batch[\"emotion\"].to(device),\n",
    "    \"emotion\": batch[\"emotion\"].to(device),\n",
    "    \"regress\": torch.stack([batch[\"valence\"], batch[\"arousal\"]], dim=1),\n",
    "    \"vote_emotion\": batch.get(\"vote_emotion\", None)\n",
    "    }\n",
    "    # TODO: Add Multilabel Fetch\n",
    "    return labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchmetrics import Accuracy, AUROC, ConcordanceCorrCoef, F1Score\n",
    "\n",
    "\n",
    "# device = torch.device('cuda:1')\n",
    "# model.to(device).load_state_dict(new_ckpt)\n",
    "# model.eval()\n",
    "model = model.model\n",
    "\n",
    "acc = Accuracy(task=\"multiclass\", num_classes=7).to(device)\n",
    "\n",
    "total_score = []\n",
    "pred = [] \n",
    "target = []\n",
    "\n",
    "pbar = tqdm(\n",
    "total=int(len(valid_dataset)/BATCH_SIZE), \n",
    "iterable = enumerate(valid_dataloadaer))\n",
    "\n",
    "total = 0 \n",
    "correct = 0 \n",
    "accumulate = 0 \n",
    "for batch_idx, batch in pbar:\n",
    "    labels = get_label(batch) # concat \n",
    "    \n",
    "    result = model(wav=batch[\"wav\"].to(device),\n",
    "            wav_mask=batch[\"wav_mask\"].to(device),\n",
    "            txt=batch[\"txt\"].to(device),\n",
    "            txt_mask=batch[\"txt_mask\"].to(device),\n",
    "            labels=labels)\n",
    "\n",
    "    # result = remove_deuce(outputs=result)\n",
    "    # result[\"emotion\"] = result[\"emotion\"].argmax(dim=1)\n",
    "    # pred.append(list(result[\"cls_pred\"].detach().cpu().numpy()))\n",
    "    # target.append(list(result[\"emotion\"].detach().cpu().numpy()))\n",
    "#     ACC_score = acc(preds=result[\"cls_pred\"], target=result[\"emotion\"]).item()\n",
    "#     print(f\"{ACC_score:.4f}\")\n",
    "#     print(torch.sum(result[\"cls_pred\"] == result[\"emotion\"]))\n",
    "    # break\n",
    "#     break\n",
    "#     total_score.append(ACC_score)\n",
    "    # save_name = os.path.join(SAVE_PATH, f'wav_txt_{batch_idx:03d}.pickle')\n",
    "    # with open(save_name, 'wb') as f:\n",
    "    #     pickle.dump(save_dict, f, pickle.HIGHEST_PROTOCOL)\n",
    "    total += result[\"emotion\"].size(0)\n",
    "    correct += torch.sum(result[\"cls_pred\"].argmax(dim=1) == result[\"emotion\"]).item()\n",
    "\n",
    "    accumulate += (correct / total)\n",
    "    accumulate /= 2 \n",
    "# print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
    "#     100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train(config: omegaconf.DictConfig) -> None:\n",
    "    module, dataloaders = setup_trainer(config)\n",
    "    \n",
    "    # Logger Setup\n",
    "    logger = hydra.utils.instantiate(config.logger)\n",
    "    logger.watch(module)\n",
    "    # Hard-code config uploading\n",
    "    wandb.config.update(\n",
    "        omegaconf.OmegaConf.to_container(config, resolve=True, throw_on_missing=True)\n",
    "    )\n",
    "\n",
    "    # Callbacks\n",
    "    callbacks: dict = hydra.utils.instantiate(config.callbacks)\n",
    "    trainer: pl.Trainer = hydra.utils.instantiate(config.trainer,\n",
    "                                                  logger=logger,\n",
    "                                                  callbacks=list(callbacks.values()))\n",
    "    trainer.fit(model=module,\n",
    "                train_dataloaders=dataloaders[\"train\"],\n",
    "                val_dataloaders=dataloaders[\"valid\"])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "erc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7ffc592dff13d4d41f223053abde961ed0db53f702fad28eadf2c0045c5935a8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
